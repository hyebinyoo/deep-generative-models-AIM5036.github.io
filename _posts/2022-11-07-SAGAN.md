---
title: "SAGAN : Self-Attention Generative Adversarial Networks"

---

# SA-GAN

## self-attenstion

- attention을 자기 자신에게 수행하는 것

- attention의 아이디어
    - decoder에서 출력 단어를 예측하는 매 시점(time step)마다 encoder에서 전체 입력 문장을 다시 한 번 참고한다는 점
    - 단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라 해당 시점에서 예측해야 할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중(attention)해서 보게 됨
- attention function
    - key-value 자료형
        - key를 통해 맵핑된 값을 찾아낼 수 있다는 특징
    
    ```python
    dict = {"2017" : "Transformer", "2018" : "BERT"}
    
    print(dict["2017"]) 
    # Transformer
    print(dict["2018"])
    # BERT
    ```
    

![attention](/SAGAN_img/Untitled.png)

- attention을 함수로 표현하면 주로 다음과 같이 표시
    
    **Attention(Q, K, V) = Attention Value**
    
- 어텐션 함수는 주어진 쿼리(query)에 대해서 모든 키(key)와의 유사도를 각각 구함
    
    구해낸 이 유사도를 맵핑되어 있는 각각의 값(value)에 반영
    
    유사도가 반영된 값(value)를 모두 더해서 리턴 = attention value
    
- Q = Query : 모든 시점의 decoder 셀에서의 은닉 상태
    
    K = Keys : 모든 시점의 enoder 셀의 은닉 상태들
    
    V = Values : 모든 시점의 encoder 셀의 은닉 상태들
    
    위
    
    위의가 기존 attention이었다면 self-attention에서는
    
    Q : 입력 문장의 모든 단어 벡터들
    
    K : 입력 문장의 모든 단어 벡터들
    
    V : 입력 문장의 모든 단어 벡터들
    
    ---
    

# Abstract

- SA-GAN : 장거리 종속성 모델링을 허용하는 이미지 생성작업(Self-Attention GAN)
- 전통적인 GAN은 저해상도 feature map에서 공간적으로 local point의 함수로 고해상도 deatil을 생성
- SAGAN은 모든 feature 위치의 cues를 사용하여 detail을 생성할 수 있음
    
    discrimnator는 이미지의 먼 부분에 있는 매우 detail한 특징이 서로 일치하는지 확인 가능
    
- 최근 연구에서는 generator conditioning이 GAN 성능에 영향을 미치는 것으로 나타남
    
    → generator에 spectral normalization을 적용. (→ 이것이 training dynamics 성능 향상 확인)
    
- SAGAN은 이전 작업보다 더 나은 성능

# 1. Introduction

- deep convolutional network에 기반한 GAN은 image synthesis에서 매우 성공적임
    - convolutional GAN에서 생성된 샘플 보면 다른 것보다 일부 이미지 클래스를 모델링하는 데 훨씬 어려움이 있음(다중 클래스 데이터셋=ImageNet)
        
        예를 들어 ImageNet GAN모델은 구조적 제약이 없는 (ex: 바다, 하늘) synthesizing에는 탁월
        
        하지만 기하학적 또는 구조적 패턴(ex: 개의 털은 잘 묘사. 발은 실패)에서는 잘 못함
        
    - 이유 : 이전 모델이 다른 이미지 영역에 대한 종속성을 모델링하기 위해 convoilution에 많이 의존한다는 것
        - convolution 연산자는 local receptive field를 가지고 있기 때문에 장거리 종속성은 여러 convolution layer를 통과한 후에만 처리 가능
            
            ![convolution](/SAGAN_img/Untitled%201.png)
            
        - 이렇게 하면 다음과 같은 다양한 이유로 장기 종속성에 대한 학습 방해
            1. 작은 모델(layer수가 적은 model)은 이를 나타내지 못함
            2. 최적화 알고리즘은 이러한 종속성을 포착하기 위해 여러 layer를 신중하게 조정하는 매개변수 값을 발견하는 데 문제 있을 수도 있음
            3. 이러한 매개변수화는 이전에 보지 못한 입력에 적용될 때 통계적으로 취약하고 실패하기 쉬움
            4. convolution kernel의 크기를 늘리면 네트워크의 표현 능력이 증가할 수 있지만, local convoltuion 구조를 사용하여 얻은 계산 및 통계 효율성도 잃게됨
    - 반면에 self-attention 모듈은 모든 위치에서 feature의 가중치 합으로 위치에서의 응답을 계산. 여기서 가중치 또는 attention  vector는 적은 계싼비용으로 계산됨.

- 이 논문에서는 self-attention mechanism을 convolutional GAN에 도입하는 SAGAN 제안
- self-attention modeul은 convolution을 보완하며 이미지 영역에 걸쳐 장거리, 다단계 종속성을 모델링하는 데 도움
- self-attion으로 무장한 generator는 모든 위치의 미세한 detatil이 이미지의 먼 부분의 미세한 detail과 신중하게 조정되는 이미지를 그릴 수 있음
- discriminator는 또한 global 이미지 구조에 복잡한 기하학적 제약을 더 정확하게 적용할 수 있음

- self-attention 외에도 network conditioning과 GAN 성능과 관련된 최근 insights를 통합
    - 잘 조절된 generator가 더 나은 성능을 보이는 경향
        
        → 이전에 discriminator에만 적용되었던 spectral normalization 기술을 사용하여 GAN generator에 좋은 conditioning을 적용할 것을 제안
        
- 제안된 self-attention mechanism과 안정화 기술의 효과를 검증하기 위해 ImageNet 데이터 세트에 대한 광범위한 실험 수행
    - SAGAN은 Inception 점수를 36.9→52.52로 높이고 Frchet Inception 거리를 27.62에서 18.65로 줄이면서 이전 작업 훨씬 능가
- attention layer의 시각화는 generator가 고정돤 모양의 로컬 영역보다는 객체 모양에 해당하는 neighborhood를 활용한다는 것을 보여줌

# 2. Realated Work

## Generative Adversarial Networks

- GAN은 image to image translation, text to image translation 포함한 다양한 이미지 생성 작업에서 큰 성공을 거둠
- 그래도 GAN의 훈련은 불안정하고 hyperparameter의 선택에 민감
- 새로운 네트워크 아키텍처를 설계하고 학습 목표를 수정하여 GAN training dynamics를 안정화하고 샘플 다양성을 개선하기 위해 여러 시도
    - dynamics, regularization 방법 추가, hyeristic tricks 추가
- 최근에는 discriminator 함수의 Lipschitz 상수를 제한하기 위해 discriminator에서 가중치 행렬의 spectral norm을 제한할 것을 제안
- projection 기반 discriminator와 결합된 spectrally normalized model은 ImageNet에서 클래스 조건부 이미지 생성을 크게 향상

## Attention Models.

- 최근 attention mechanism은 global 종속성을 포착해야 하는 모델의 필수적인 부분이 되었음
    - 특히 self-attention은 intra-attention이라고도 하며, 동일한 sequence내의 모든 position에 주의를 기울여 sequence의 position에서 응답 계산
    - 여러 연구에서 self attension 사용
- 이러한 진전에도 불구하고 GAN에서 self-attention은 아직 탐구되지 않음
- SAGAN은 이미재의 내부 표현 내에서 global 장거리 종속성을 효율적으로 찾는 방법을 배움

# 3. Self-Attention Generative Adversarial Networks

- 이미지 생성을 위한 대부분의 GAN 기반 모델은 convolution layer를 사용하여 구축됨
    
    ![convolution layer](/SAGAN_img/Untitled%202.png)
    
- convolution은 local neighborhood에서 정보를 처리하므로 convolution layer만 사용하는 것인 이미지 장거리 종속성 모델링 하는데 계산적으로 비효율적
- 이 section에서 GAN에 self-attention을 도입하기 위해 non-local model을 적용하여 generator와 discriminator가 광범위하게 분리된 공간 영역간의 관계를 효율적으로 modeling할 수 있도록 함

![fig2](/SAGAN_img/Untitled%203.png)

⨂ : 행렬곱. softmax 연산자는 각 열에서 수행됨

- 이전 hidden layer x⋴R^(CxN)의 이미지 feature는 먼저 두 개의 feature map f, g로 변환되어 attention 계산
    - 여기서 $f(x)=W_f(x), g(x)=W_g(x)$
    - β_(j,i) : j번째 영역을 synthesizing할 때 모델이 i번째 위치에 attend 하는 정도
    
    ![eq 1](/SAGAN_img/Untitled%204.png)
    
    - C : channel의 개수, N : 이전 hidden layer의 feature 위치의 개수
    - attenion layer의 출력은 $o=(o_1, o_2, ..., o_j, ..., o_N)$∊R^(CxN)
    
    ![eq 2](/SAGAN_img/Untitled%205.png)
    
    - 위의 식에서 $W_g, W_f, W_h, W_V$는 1x1 convolution으로 구현되는 학습된 가중치 행렬
    - ImageNet에서 몇 번의 훈련 epoch 후에 C의 채널 수를 1,2,4,8로 줄일 때 성능이 크게 저하되는 것 발견하지 못함
        
        → 메모리 효율성을 위해 모든 실험에서 k=C=8을 선택
        
    - 또한, attention layer의 출력을 scale 매개변수로 더 곱하고 입력 feature map을 다시 추가
    - 최종출력 :
        
        ![eq 3](/SAGAN_img/Untitled%206.png)
        
        - γ : 학습 가능한 scalar. 0으로 초기화
        - 학습 가능한 γ을 도입하면 네트워크가 먼저 local neighborhood의 신호에 의존 → 더 쉽기 때문!
        - 그 다음 점차적으로 non-local evidence에 더 많은 가중치를 할당하는 방법을 학습
        - 이를 하는 이유 : 쉬윈 작업을 먼저 배우고 작업의 복잡성을 점진적으로 증가시키기 원함
    - SAGAN에저 제안된 self-attention module은 generator와 discriminator 모두에 적용되었으며 적대적 손실의 hinge 버전을 최소화하여 교대로 학습됨
        
        ![eq 4](/SAGAN_img/Untitled%207.png)
        

# 4. Techniques to Stabilize the Training of GANs

- 까다로운 데이터 세트에 대한 GAN 교육을 안정화하기 위해 두 가지 기술 조사
    1. generator와 discriminator에서 spetral normalization을 사용
    2. TTUR(twotimescale update rule)이 효과적임을 확인했으며 특히 정규화된 discriminator의 느린 학습을 해결하기 위해 이를 사용
    

## 4.1 Spectral normalization for both generator and discriminator

- Miyato는 원래 discriminator 네트워크에 spetral normalization을 적용하여 GAN의 훈련을 안정화하는 것을 제안
    - 그렇게 하면 각 레이어의 spectral norm을 제한하여 discriminator의 Lipschitz 상수를 제한
    - 다른 normalization 기술과 비교하여 spectral normalization은 추가 하이퍼 매개변수 조정이 필요하지 않음
        
        (모든 가중치 레이어의 spectral norm을 1로 설정하면 실제로 일관되게 잘 수행됨)
        
    - 계산 비용이 상대적으로 작음
- 저자는 generator의 conditioning이 GAN 성능에서 중요한 인과요인이라는 최근 증거에 기초하여 generator가 spetral norm의 이점을 얻을 수도 있다고 주장
    - generation의 spectral normalization은 매개변수 크기의 상승을 방지하고 비정상적인 gradient 방지
- generator와 discriminator 모두의 spectral norm가 generator 업데이트 당 더 적은 discriminator 업데이트를 사용할 수 있게 하여 훈련의 계산 비용을 크게 줄일 수 있다는 것을 경험적으로 발견
- 이 접근방식은 또한 더 안정적인 훈련 동작 보여줌

## 4.2 Imbalanced learning rate for generator and discriminator updates

- 이전 연구에서는 discriminator의 regularization는 종종 GAN의 학습 프로세스를 느리게 함
- 실제로 정규화된 discriminator를 사용하는 방법은 일반적으로 훈련 중 generator 업데이트 단계당 discriminator 업데이트 단계가 필요
- 독립적으로 Heusel은 generator와 discriminator에 별도의 학습률(TTUR)을 사용하는 것을 옹호
- 이 논문에서는 특히 TTUR을 사용하여 정규화된 discriminator에서 느린 학습 문제를 보완하여 generator 단계 당 더 적은 discriminator 단계를 사용할 수 있도록 제안
- 이 접근방식을 사용하면 동일한 wall-clock 시간에서 더 나은 결과 생성

# 5. Experiments

- 논문 방법을 평가하기 위해 LSVRC2012(ImageNet) 데이터 세트에 대해 실험 수행
- 5.1에서 GAN의 훈련을 안정화하기 위해 제안된두 가지 기술의 효율성을 평가하기 위해 설계된 실험 제시
- 5.2에서 self-attention 메커니즘
- 5.3에서 이미지 생성 작업에 대한 최신 방법과 비교
    - 모델은 동기식 SGD를 사용하여 각각 4개의 GPU에서 대략 2주동안 훈련됨(비동기식 SGD에는 잘 알려진 어려움이 있으므로)

### Evaluation metrics

- 정량적 평가를 위해 inception score와 fid를 선택
- inception score는 조건부 클래스 분포와 주변 클래스 분포간의 KL divergence를 계산
    - inception 점수가 높을수록 더 나은 이미지 품질
    - inception score는 널리 사용되어 이전 작업과 결과를 비교할 수 있기 때문에 포함
    - inception score에는 심각한 제한이 있음
        - 모델이 특정 클래스에 속하는 것으로 확실하게 인식될 수 있는 샘플을 생성하고, 모델이 세부 사항의 사실성 또는 클래스 내의 다양성을 평가할 필요가 없는 많은 클래스에서 샘플을 생성하도록 하기 위한 것
- FID는 보다 원칙적이고 포괄적인 메트릭스.
    
    생성된 샘플의 현실성과 변동성을 평가할 때 인간의 평가와 더 일치
    
    - FID는 생성된 이미지와 Inception-v3 네트워크 feature map에서 실제 이미지 사이의 Wasserstein-2 거리를 계산
    - 전체 데이터 분포(즉, ImageNet의 모든 1000개 이미지 클래스)에 대해 계산된 FID 외에도 생성된 이미지와 각 클래스 내 데이터 세트 이미지 사이의 FID를 계산(=intra FID)
    - FID 및 내부 FID값이 낮을수록 합성 데이터 분포와 실제 데이터 분포 사이의 거리가 더 가까움
    - 모든 실험에서 50k 샘플은 각 모델에 대해 무작위로 생성되어 시작 점수, FID 및 내부 FID 계산

### Network structures and implementation detatils

- 우리가 훈련하는 모든 SAGAN 모델은 128x128 이미지를 생성하도록 설계됨
- 기본적으로 spectral normalization는 generator와 discriminator 모두의 layer에 사용됨
- SAGAN은 generator에서 조건부 배치 정규화를 사용하고 discriminator에서 projection을 사용
- 모든 모델에 대해 Adam optimizer를 사용
    - 훈련의 경우 $β_1=0, β_2=0.9$
- 기본적으로 discriminator의 학습률은 0.0004이고 generator의 학습률은 0.0001

## 5.1 Evaluating the proposed stabilization techinques

- 이 섹션에서는 제안된 안정화 기술, 즉 generator에 SN을 적용하고 TTUR을 활용하는 방법의 효율성을 평가하기 위한 실험 수행
- 그림 3에서 이 모델은 최신 이미지 생성 방법과 비교한다.
    - 이 베이스라인 모델에서 SN은 discriminator에서만 사용됨
    - D와 G에 대해 1:1 업데이트롤 훈련하면 그림 3의 가장 왼쪽 하위 그림과 같이 훈련이 매우 불안정해짐 → 훈련 초기의 mode collapse를 나타냄
    - 예를 들어 그림 4의 왼쪽 상단 하위 그림은 10k번째 iteration에서 기준 모델에 의해 무작위로 생상된 일부 이미지를 보여줌
    - 원본 baseline 논문에서는 D와 G에 의해 5:1 불균형 업데이트를 사용하여 이러한 불안정한 훈련 동작을 크게 완화했지만 1:1 균형 업데이트로 안정적으로 훈련하는 기능은 모델의 훈련속도를 향상시키기 위해 바람직
        
        → 따라서 우리의 제안된 기술을 사용하면 동일한 wall-clock 시간에서 모델이 더 나은 결과를 생성할 수 있음
        
    - 이를 감안할 때 generator와 discriminator에 적합한 업뎅트 비율을 검색할 필요가 없음
    - 그림 3의 중간 하위 그림에서 볼 수 있듯이 generator와 discriminator 모두에 SN을 추가하면 1:1 균형 업데이트로 훈련된 경우에도 “SN on G/D” 모델이 크게 안정화됨
- 하지만 샘플의 품질은 훈련 중에 단조롭게 향상되지 않음
    - 예를 들어 FID 및 IS로 측정한 이미지 품질은 260k번째 iteration에서 떨어지기 시작
    - 다른 iteration에서 이 모델에 의해 무작위로 생성된 예시 이미지는 그림 4에서 찾을 수 있음
- 우리가 D와 G를 훈련시키기 위해 불균형 학습률을 적용할 때 우리 모델 “SN on G/D + TTUR”에 의해 생성된 이미지의 품질은 전체 훈련 과정에서 단조롭게 향상됨
- 그림 3과 그림 4에서 불 수 있듯이 백만번의 훈련 iteration동안 샘플 품질이나 FID 또는 Inception 점수의 유의미한 감소를 관찰하지 못함
    
    → 따라서 정량적 결과와 질적 결과 모두 GAN의 훈련을 위해 제안된 안정화 기술의 효과를 보여줌
    
- 그들은 또한 두 기술의 효과가 적어도 부분적으로는 부가적이라는 것을 보여줌
- 나머지 실험에서 모든 모델은 G와 D 모두에 SN을 사용하고 불균형 학습률을 사용하여 1:1 업데이트로 G와 D를 훈련

- 결과사진
    
    ![fig 3](/SAGAN_img/Untitled%208.png)
    
    3개의 비교군에 대한 FID와 Inception score
    

![fig 4](/SAGAN_img/Untitled%209.png)

baseline(SN on D), SN on G/D, SN on G/D + TTUR 비교

![fig 5](/SAGAN_img/Untitled%2010.png)

각 쿼리에대해한 attention map으로, query에 대해서 가장 집중해서 보는 지역을 보여주게 됨

![fig 6](/SAGAN_img/Untitled%2011.png)

가장 왼쪽의 괄호 : FID 점수(SAGAN, 최신모델(cGAN with projection in discriminator))